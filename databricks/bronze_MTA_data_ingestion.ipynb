{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c00536b-1947-4ee7-a69d-887c74276ab0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01ab2b00-34d5-40ba-9c77-1fdaaf65a203",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "EH_CONNECTION_STRING = \"My-connection-string\"\n",
    "\n",
    "eh_kafka_conf = {\n",
    "  'kafka.bootstrap.servers': 'mta-real-time.servicebus.windows.net:9093',\n",
    "  'kafka.sasl.mechanism': 'PLAIN',\n",
    "  'kafka.security.protocol': 'SASL_SSL',\n",
    "  'kafka.sasl.jaas.config': f'kafkashaded.org.apache.kafka.common.security.plain.PlainLoginModule required username=\"$ConnectionString\" password=\"{EH_CONNECTION_STRING}\";'\n",
    "}\n",
    "\n",
    "raw_stream_df = (spark\n",
    "  .readStream\n",
    "  .format(\"kafka\")\n",
    "  .options(**eh_kafka_conf)\n",
    "  .option(\"subscribe\", \"bus-positions-topic\")\n",
    "  .option(\"startingOffsets\", \"earliest\")\n",
    "  .load()\n",
    ")\n",
    "\n",
    "json_stream_df = raw_stream_df.selectExpr(\"CAST(value AS STRING)\", \"timestamp as kafka_timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f18d5ca6-9367-427f-a1e0-73266e69c240",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "trip_update_schema_bronze = StructType([\n",
    "    StructField(\"trip_id\", StringType(), True),\n",
    "    StructField(\"start_date\", StringType(), True),\n",
    "    StructField(\"route_id\", StringType(), True),\n",
    "    StructField(\"direction_id\", StringType(), True),\n",
    "    StructField(\"vehicle_id\", StringType(), True),\n",
    "    StructField(\"update_timestamp\", StringType(), True),\n",
    "    StructField(\"trip_delay_seconds\", StringType(), True),\n",
    "    StructField(\"stop_sequence\", StringType(), True),\n",
    "    StructField(\"stop_id\", StringType(), True),\n",
    "    StructField(\"arrival_time\", StringType(), True),\n",
    "    StructField(\"departure_time\", StringType(), True),\n",
    "    StructField(\"message_type\", StringType(), True)\n",
    "])\n",
    "\n",
    "bus_position_schema_bronze = StructType([\n",
    "    StructField(\"vehicle_id\", StringType(), True),\n",
    "    StructField(\"trip_id\", StringType(), True),\n",
    "    StructField(\"start_date\", StringType(), True),\n",
    "    StructField(\"route_id\", StringType(), True),\n",
    "    StructField(\"direction_id\", StringType(), True),\n",
    "    StructField(\"stop_id\", StringType(), True),\n",
    "    StructField(\"latitude\", StringType(), True),\n",
    "    StructField(\"longitude\", StringType(), True),\n",
    "    StructField(\"bearing\", StringType(), True),\n",
    "    StructField(\"timestamp\", StringType(), True),\n",
    "    StructField(\"message_type\", StringType(), True)\n",
    "])\n",
    "\n",
    "alert_schema_bronze = StructType([\n",
    "    StructField(\"alert_id\", StringType(), True),\n",
    "    StructField(\"start_time\", StringType(), True), \n",
    "    StructField(\"end_time\", StringType(), True),   \n",
    "    StructField(\"header_text\", StringType(), True),\n",
    "    StructField(\"description_text\", StringType(), True),\n",
    "    StructField(\"agency_id\", StringType(), True),\n",
    "    StructField(\"route_id\", StringType(), True),\n",
    "    StructField(\"stop_id\", StringType(), True),\n",
    "    StructField(\"trip_route_id\", StringType(), True),\n",
    "    StructField(\"trip_direction_id\", StringType(), True),\n",
    "    StructField(\"message_type\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d223f12b-b46b-45ed-be6a-57a32554aa95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json, col\n",
    "\n",
    "common_schema = StructType([StructField(\"message_type\", StringType())])\n",
    "typed_stream_df = json_stream_df.withColumn(\"parsed_value\", from_json(col(\"value\"), common_schema))\n",
    "\n",
    "trip_updates_bronze_df = (typed_stream_df\n",
    "  .filter(col(\"parsed_value.message_type\") == \"trip_update\")\n",
    "  .withColumn(\"data\", from_json(col(\"value\"), trip_update_schema_bronze))\n",
    "  .select(\"kafka_timestamp\", \"data.*\")\n",
    ")\n",
    "\n",
    "bus_positions_bronze_df = (typed_stream_df\n",
    "  .filter(col(\"parsed_value.message_type\") == \"bus_position\")\n",
    "  .withColumn(\"data\", from_json(col(\"value\"), bus_position_schema_bronze))\n",
    "  .select(\"kafka_timestamp\", \"data.*\")\n",
    ")\n",
    "\n",
    "alerts_bronze_df = (typed_stream_df\n",
    "  .filter(col(\"parsed_value.message_type\") == \"alert\")\n",
    "  .withColumn(\"data\", from_json(col(\"value\"), alert_schema_bronze))\n",
    "  .select(\"kafka_timestamp\", \"data.*\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a96343a0-55ad-4399-aa0f-2951a9d4795d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.connect.streaming.query.StreamingQuery at 0x7f1880753980>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRIP_UPDATES_BRONZE_PATH = \"/mta_project/delta/bronze/trip_updates\"\n",
    "BUS_POSITIONS_BRONZE_PATH = \"/mta_project/delta/bronze/bus_positions\"\n",
    "ALERTS_BRONZE_PATH = \"/mta_project/delta/bronze/alerts\"\n",
    "\n",
    "(trip_updates_bronze_df.writeStream\n",
    "  .format(\"delta\")\n",
    "  .outputMode(\"append\")\n",
    "  .option(\"checkpointLocation\", f\"{TRIP_UPDATES_BRONZE_PATH}/_checkpoints\")\n",
    "  .trigger(availableNow=True)\n",
    "  .start(TRIP_UPDATES_BRONZE_PATH)\n",
    ")\n",
    "\n",
    "(bus_positions_bronze_df.writeStream\n",
    "  .format(\"delta\")\n",
    "  .outputMode(\"append\")\n",
    "  .option(\"checkpointLocation\", f\"{BUS_POSITIONS_BRONZE_PATH}/_checkpoints\")\n",
    "  .trigger(availableNow=True)\n",
    "  .start(BUS_POSITIONS_BRONZE_PATH)\n",
    ")\n",
    "\n",
    "(alerts_bronze_df.writeStream\n",
    "  .format(\"delta\")\n",
    "  .outputMode(\"append\")\n",
    "  .option(\"checkpointLocation\", f\"{ALERTS_BRONZE_PATH}/_checkpoints\")\n",
    "  .trigger(availableNow=True)\n",
    "  .start(ALERTS_BRONZE_PATH)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3823d5e2-6118-41f7-b690-4a326dd42630",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Bronze MTA data Ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
